{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1eed963e-0efe-4135-a7e8-735eac7de856",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d99cbad-c33a-46f2-becd-fdd6b5c03621",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definindo configurações dos Containers\n",
    "SRC_STORAGE_ACCOUNT = dbutils.secrets.get(scope=\"secrets-kv\", key=\"storage-account\")\n",
    "SRC_SAS_TOKEN = dbutils.secrets.get(scope=\"secrets-kv\", key=\"blob-sas-access\")\n",
    "\n",
    "containers_config = {\n",
    "    \"BALANCE\": {\n",
    "        \"container\": dbutils.secrets.get(scope=\"secrets-kv\", key=\"src-balance-container\"),\n",
    "        \"account\": SRC_STORAGE_ACCOUNT,\n",
    "        \"sas\": SRC_SAS_TOKEN\n",
    "    },\n",
    "    \"CNPJ\": {\n",
    "        \"container\": dbutils.secrets.get(scope=\"secrets-kv\", key=\"src-cnpj-container\"),\n",
    "        \"account\": SRC_STORAGE_ACCOUNT,\n",
    "        \"sas\": SRC_SAS_TOKEN\n",
    "    }\n",
    "}\n",
    "# Dicionário vazio para guardar os objetos instanciados\n",
    "containers_registry = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1559f64-cf74-4bf1-ad8f-52ec82d662b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Instanciando Objetos\n",
    "for container, config in containers_config.items():\n",
    "    # Instancia o objeto para cada container\n",
    "    obj = AzureContainer(\n",
    "        storage_account=config[\"account\"],\n",
    "        container_name=config[\"container\"],\n",
    "        sas_token=config[\"sas\"]\n",
    "    )\n",
    "    \n",
    "    # Guarda o objeto no dicionário usando o apelido como chave\n",
    "    containers_registry[container] = obj\n",
    "\n",
    "    print(f\"✅ Container '{container}' configurado com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd8f3385-e236-4a55-bb29-e24e6b80ab8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lista para armazenar dicionários com os metadados\n",
    "lista_arquivos_processada = []\n",
    "\n",
    "for nome, obj in containers_registry.items():\n",
    "    # Obtém a lista de arquivos do container\n",
    "    arquivos = obj.get_files_list()\n",
    "    \n",
    "    for arq in arquivos:\n",
    "        lista_arquivos_processada.append({\n",
    "            \"path\": arq.path,\n",
    "            \"name\": arq.name,\n",
    "            \"size\": arq.size,\n",
    "            \"modificationTime\": arq.modificationTime,\n",
    "            \"container_name\": nome\n",
    "        })\n",
    "\n",
    "    print(f\"✅ Metadados coletados de: {nome.upper()}\")\n",
    "\n",
    "# Criando o DataFrame com os arquivos\n",
    "df_inventario = spark.createDataFrame(lista_arquivos_processada)\n",
    "\n",
    "# Convertendo modificationTime para um formato mais amigável\n",
    "df_inventario = df_inventario.withColumn(\n",
    "    \"modificationTime\", \n",
    "    (F.col(\"modificationTime\") / 1000).cast(\"timestamp\")\n",
    ")\n",
    "\n",
    "display(df_inventario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "585b42b8-c01d-4dfa-b3b0-815bbcba4fda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Recuperando Chaves de Acesso\n",
    "TGT_STORAGE_ACCOUNT = dbutils.secrets.get(scope=\"secrets-kv\", key=\"tgt-storage-account\")\n",
    "TGT_CONTAINER = dbutils.secrets.get(scope=\"secrets-kv\", key=\"tgt-container\")\n",
    "TGT_SAS_TOKEN = dbutils.secrets.get(scope=\"secrets-kv\", key=\"tgt-sas-token\")\n",
    "\n",
    "# Configuring SAS for Lakehouse Container\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.sas.{TGT_CONTAINER}.{TGT_STORAGE_ACCOUNT}.blob.core.windows.net\",\n",
    "    TGT_SAS_TOKEN\n",
    ")\n",
    "\n",
    "# Definindo Path base do LakeHouse\n",
    "BASE_PATH = f\"wasbs://{TGT_CONTAINER}@{TGT_STORAGE_ACCOUNT}.blob.core.windows.net\"\n",
    "\n",
    "BRONZE_BASE_PATH = f\"{BASE_PATH}/bronze\"\n",
    "CONTROL_TABLE_PATH = f\"{BASE_PATH}/metadata/control_table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcd70c4a-5065-43d1-ac7e-b97452444096",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Verifica se a tabela existe, se não, cria com o esquema das suas colunas\n",
    "if not dbutils.fs.ls(CONTROL_TABLE_PATH):\n",
    "    df_init = spark.createDataFrame([], \"originator STRING, table_name STRING, input_file_name STRING\") \\\n",
    "                   .withColumn(\"last_ingestion_timestamp\", current_timestamp())\n",
    "    df_init.write.format(\"delta\").mode(\"overwrite\").save(CONTROL_TABLE_PATH)\n",
    "    print(\"Tabela de controle inicializada.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Intancia_Containers",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
