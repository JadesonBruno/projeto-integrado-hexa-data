# üîÑ Refatora√ß√£o: Suporte a ZIP + Wildcards + Sem Unity Catalog

## üìã Resumo das Mudan√ßas

Este documento descreve as melhorias implementadas no pipeline para:
1. ‚úÖ Funcionar **sem Unity Catalog** (usa databases tradicionais)
2. ‚úÖ Suportar **nomenclatura vari√°vel** de arquivos (wildcards)
3. ‚úÖ **Descompactar ZIPs automaticamente**

---

## üéØ Principais Mudan√ßas

### **1. Remo√ß√£o do Unity Catalog**

**Antes:**
```python
CATALOG = "comercio_exterior"
SCHEMA_BRONZE = "bronze"
target_table = f"{Config.CATALOG}.{Config.SCHEMA_BRONZE}.{table_name}"
# Exemplo: "comercio_exterior.bronze.fct_exp"
```

**Depois:**
```python
DATABASE_BRONZE = "bronze"
target_table = f"{Config.DATABASE_BRONZE}.{table_name}"
# Exemplo: "bronze.fct_exp"
```

**Comandos de cria√ß√£o:**
```sql
-- Antes (Unity Catalog)
CREATE SCHEMA comercio_exterior.bronze;

-- Depois (Database tradicional)
CREATE DATABASE IF NOT EXISTS bronze;
```

---

### **2. Suporte a Wildcards (Nomenclatura Vari√°vel)**

**Problema resolvido:**
```
Janeiro: EXP_2025_01.csv
Fevereiro: EXPORTACAO_202502.csv  ‚Üê Nome diferente!
Mar√ßo: exp_marco_2025.csv          ‚Üê Totalmente diferente!
```

**Solu√ß√£o:**
```python
FILE_PATTERNS = {
    "fct_exp": [
        "EXP*.csv",          # Pega EXP_2025_01.csv
        "EXPORTACAO*.csv",   # Pega EXPORTACAO_202502.csv
        "exp*.csv",          # Pega exp_marco_2025.csv
        "exportacao*.csv"
    ],
    "estabelecimentos": [
        "*.ESTABELE",         # Formato original Receita Federal
        "*ESTABELE*.csv",     # Varia√ß√µes
        "*estabelecimento*.csv"
    ]
}
```

**Como funciona:**
- Autoloader tenta cada pattern sequencialmente
- Processa qualquer arquivo que corresponda a qualquer pattern
- Checkpoint garante que n√£o duplica dados

---

### **3. Descompacta√ß√£o Autom√°tica de ZIPs**

**Estrutura de Landing Zone:**

```
/mnt/landing/
‚îú‚îÄ‚îÄ raw/                           ‚Üê ZIPs chegam aqui
‚îÇ   ‚îî‚îÄ‚îÄ cnpj/
‚îÇ       ‚îú‚îÄ‚îÄ Empresas/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ dados_empresas.zip
‚îÇ       ‚îî‚îÄ‚îÄ Estabelecimentos/
‚îÇ           ‚îî‚îÄ‚îÄ estabelecimentos_01.zip
‚îÇ
‚îú‚îÄ‚îÄ extracted/                     ‚Üê CSVs extra√≠dos (Autoloader l√™)
‚îÇ   ‚îî‚îÄ‚îÄ cnpj/
‚îÇ       ‚îú‚îÄ‚îÄ Empresas/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ F.K032001K.D11101.EMPRECSV
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ F.K032001K.D11102.EMPRECSV
‚îÇ       ‚îî‚îÄ‚îÄ Estabelecimentos/
‚îÇ           ‚îî‚îÄ‚îÄ K3241.K03200Y0.D10810.ESTABELE
‚îÇ
‚îî‚îÄ‚îÄ processed/                     ‚Üê ZIPs movidos ap√≥s extra√ß√£o
    ‚îî‚îÄ‚îÄ cnpj/
        ‚îî‚îÄ‚îÄ Empresas/
            ‚îî‚îÄ‚îÄ dados_empresas.zip
```

**Fluxo autom√°tico:**

1. ZIP √© detectado em `/mnt/landing/raw/`
2. Fun√ß√£o `unzip_files()` extrai para `/mnt/landing/extracted/`
3. Autoloader processa CSVs em `/extracted/`
4. ZIP √© movido para `/mnt/landing/processed/`

**Controle:**
```python
# Habilitar/desabilitar via widget
dbutils.widgets.dropdown("auto_unzip", "true", ["true", "false"], "Auto Unzip")

# Ou via configura√ß√£o
Config.AUTO_UNZIP = True  # ou False
```

---

## üìÅ Arquivos Modificados

### **config_utils.py**
- ‚úÖ Removido `CATALOG`, adicionado `DATABASE_BRONZE/SILVER/GOLD`
- ‚úÖ Adicionado `FILE_PATTERNS` com wildcards
- ‚úÖ Nova fun√ß√£o `unzip_files()` para descompactar ZIPs
- ‚úÖ Nova fun√ß√£o `get_source_paths()` para gerar paths com wildcards
- ‚úÖ Fun√ß√£o `get_or_create_table()` usa paths DBFS em vez de Unity Catalog

### **bronze_balanca_comercial.py**
- ‚úÖ Nova fase de descompacta√ß√£o antes do Autoloader
- ‚úÖ `ingest_with_autoloader()` usa m√∫ltiplos patterns
- ‚úÖ Schema evolution habilitado: `.option("cloudFiles.schemaEvolutionMode", "addNewColumns")`

### **bronze_cnpj.py**
- ‚úÖ Descompacta√ß√£o de ZIPs da Receita Federal
- ‚úÖ Suporte a patterns vari√°veis (`.EMPRECSV`, `*empresa*.csv`, etc.)
- ‚úÖ Encoding UTF-8 para Estabelecimentos

### **silver_incremental.py**
- ‚úÖ Refer√™ncias ao Unity Catalog substitu√≠das por databases
- ‚úÖ Sem mudan√ßas na l√≥gica CDF

### **gold_agregacoes.py**
- ‚úÖ Refer√™ncias ao Unity Catalog substitu√≠das por databases
- ‚úÖ Sem mudan√ßas na l√≥gica de agrega√ß√£o

### **data_quality_validation.py**
- ‚úÖ Refer√™ncias ao Unity Catalog substitu√≠das por databases

---

## üöÄ Como Usar

### **Setup Inicial**

```sql
-- Criar databases
CREATE DATABASE IF NOT EXISTS bronze;
CREATE DATABASE IF NOT EXISTS silver;
CREATE DATABASE IF NOT EXISTS gold;
CREATE DATABASE IF NOT EXISTS control;

-- Criar tabelas de controle
CREATE TABLE IF NOT EXISTS control.pipeline_execution (
    execution_id STRING,
    pipeline_name STRING,
    layer STRING,
    start_time TIMESTAMP,
    end_time TIMESTAMP,
    status STRING,
    records_processed BIGINT,
    error_message STRING,
    metadata MAP<STRING, STRING>
) USING DELTA;

CREATE TABLE IF NOT EXISTS control.cdf_watermark (
    table_name STRING,
    layer STRING,
    last_processed_version BIGINT,
    last_processed_timestamp TIMESTAMP,
    updated_at TIMESTAMP
) USING DELTA;
```

### **Estrutura de Pastas (DBFS)**

```bash
# Criar estrutura de landing
dbutils.fs.mkdirs("/mnt/landing/raw/balancacomercial")
dbutils.fs.mkdirs("/mnt/landing/raw/cnpj")
dbutils.fs.mkdirs("/mnt/landing/extracted")
dbutils.fs.mkdirs("/mnt/landing/processed")

# Criar pastas de dados
dbutils.fs.mkdirs("/mnt/datalake/bronze")
dbutils.fs.mkdirs("/mnt/datalake/silver")
dbutils.fs.mkdirs("/mnt/datalake/gold")

# Criar pastas de checkpoint
dbutils.fs.mkdirs("/mnt/checkpoints")
```

### **Upload de Arquivos**

**Op√ß√£o 1: Arquivos CSV direto**
```python
# Copiar CSVs para a pasta extracted (pula etapa de unzip)
dbutils.fs.cp("file:/local/EXP_2025_01.csv", "/mnt/landing/extracted/balancacomercial/EXP/")

# Executar Bronze (auto-unzip desabilitado)
%run ./bronze_balanca_comercial
```

**Op√ß√£o 2: Arquivos ZIP**
```python
# Copiar ZIPs para pasta raw
dbutils.fs.cp("file:/local/dados.zip", "/mnt/landing/raw/balancacomercial/EXP/")

# Executar Bronze (auto-unzip habilitado - padr√£o)
%run ./bronze_balanca_comercial
# O notebook automaticamente:
# 1. Detecta o ZIP
# 2. Descompacta para /extracted/
# 3. Processa com Autoloader
# 4. Move ZIP para /processed/
```

### **Execu√ß√£o Manual**

```python
# Bronze Balan√ßa Comercial
%run ./bronze_balanca_comercial

# Bronze CNPJ
%run ./bronze_cnpj

# Silver (processamento incremental via CDF)
%run ./silver_incremental

# Gold (agrega√ß√µes incrementais)
%run ./gold_agregacoes

# Valida√ß√£o
%run ./data_quality_validation
```

---

## üéõÔ∏è Configura√ß√µes Importantes

### **Habilitar/Desabilitar Auto-Unzip**

**Via Widget (na execu√ß√£o):**
```python
dbutils.widgets.dropdown("auto_unzip", "true", ["true", "false"], "Auto Unzip")
```

**Via Config (hard-coded):**
```python
# Em config_utils.py
Config.AUTO_UNZIP = False  # Desabilitar descompacta√ß√£o
```

### **Adicionar Novos Wildcards**

```python
# Em config_utils.py
FILE_PATTERNS = {
    "fct_exp": [
        "EXP*.csv",
        "EXPORTACAO*.csv",
        "NOVO_PADRAO*.csv"  # ‚Üê Adicione aqui
    ]
}
```

### **Schema Evolution**

Se as colunas dos CSVs mudarem:

```python
# J√° habilitado no c√≥digo
.option("cloudFiles.schemaEvolutionMode", "addNewColumns")
.option("mergeSchema", "true")

# Comportamento:
# - Novas colunas: Adicionadas automaticamente (preenchidas com NULL nos registros antigos)
# - Colunas removidas: Ignoradas (dados antigos mantidos)
# - Tipos diferentes: Usa tipo mais gen√©rico (ex: INT ‚Üí STRING)
```

---

## üß™ Testes

### **Teste 1: Nomenclatura Vari√°vel**

```python
# Criar arquivos com nomes diferentes
dbutils.fs.put("/mnt/landing/extracted/balancacomercial/EXP/EXP_2025_01.csv", "CO_ANO;CO_MES;VL_FOB\n2025;01;1000")
dbutils.fs.put("/mnt/landing/extracted/balancacomercial/EXP/EXPORTACAO_202502.csv", "CO_ANO;CO_MES;VL_FOB\n2025;02;2000")
dbutils.fs.put("/mnt/landing/extracted/balancacomercial/EXP/exp_marco.csv", "CO_ANO;CO_MES;VL_FOB\n2025;03;3000")

# Executar Bronze
%run ./bronze_balanca_comercial

# Verificar
spark.sql("SELECT * FROM bronze.fct_exp ORDER BY CO_MES").show()
# Deve mostrar 3 registros (janeiro, fevereiro, mar√ßo)
```

### **Teste 2: Descompacta√ß√£o de ZIP**

```python
# Criar ZIP localmente
import zipfile
with zipfile.ZipFile('/tmp/teste.zip', 'w') as z:
    z.writestr('EXP_2025_04.csv', 'CO_ANO;CO_MES;VL_FOB\n2025;04;4000')

# Upload para raw
dbutils.fs.cp("file:///tmp/teste.zip", "/mnt/landing/raw/balancacomercial/EXP/")

# Executar Bronze
%run ./bronze_balanca_comercial

# Verificar:
# 1. ZIP foi movido para /processed/
# 2. CSV extra√≠do para /extracted/
# 3. Dados ingeridos no Bronze
spark.sql("SELECT * FROM bronze.fct_exp WHERE CO_MES = '04'").show()
```

### **Teste 3: Idempot√™ncia**

```python
# Executar Bronze 2x seguidas
%run ./bronze_balanca_comercial
count1 = spark.sql("SELECT COUNT(*) FROM bronze.fct_exp").collect()[0][0]

%run ./bronze_balanca_comercial
count2 = spark.sql("SELECT COUNT(*) FROM bronze.fct_exp").collect()[0][0]

# count1 deve ser igual a count2 (n√£o duplicou)
assert count1 == count2, "Pipeline n√£o √© idempotente!"
```

---

## ‚ö†Ô∏è Troubleshooting

### **Erro: "Database does not exist"**

```sql
-- Criar databases manualmente
CREATE DATABASE IF NOT EXISTS bronze;
CREATE DATABASE IF NOT EXISTS silver;
CREATE DATABASE IF NOT EXISTS gold;
CREATE DATABASE IF NOT EXISTS control;
```

### **Erro: "Path does not exist" no unzip**

```python
# Criar estrutura de landing
dbutils.fs.mkdirs("/mnt/landing/raw")
dbutils.fs.mkdirs("/mnt/landing/extracted")
dbutils.fs.mkdirs("/mnt/landing/processed")
```

### **Arquivos n√£o sendo processados**

```python
# Verificar se arquivos existem
dbutils.fs.ls("/mnt/landing/extracted/balancacomercial/EXP/")

# Resetar checkpoint (√∫ltima op√ß√£o)
dbutils.fs.rm("/mnt/checkpoints/bronze/fct_exp", recurse=True)

# Re-executar
%run ./bronze_balanca_comercial
```

### **ZIP n√£o descompacta**

```python
# Verificar se auto-unzip est√° habilitado
print(Config.AUTO_UNZIP)  # Deve ser True

# Executar descompacta√ß√£o manualmente
unzip_files("balancacomercial/EXP")
```

---

## üìä Compara√ß√£o: Antes vs Depois

| Aspecto | Antes | Depois |
|---------|-------|--------|
| **Unity Catalog** | Obrigat√≥rio | ‚ùå N√£o usa |
| **Nomenclatura fixa** | EXP_2025_01.csv | ‚úÖ EXP*, EXPORTACAO*, exp* |
| **ZIP** | Manual | ‚úÖ Autom√°tico |
| **Schema changes** | Erro | ‚úÖ Evolution autom√°tico |
| **Complexity** | Alta | ‚úÖ Baixa |

---

## ‚úÖ Checklist de Implementa√ß√£o

- [ ] Criar databases (`bronze`, `silver`, `gold`, `control`)
- [ ] Criar estrutura de landing (`/raw`, `/extracted`, `/processed`)
- [ ] Upload dos notebooks refatorados
- [ ] Configurar wildcards para seus padr√µes de arquivo
- [ ] Testar descompacta√ß√£o de ZIP
- [ ] Testar nomenclatura vari√°vel
- [ ] Validar idempot√™ncia
- [ ] Configurar Workflow (se aplic√°vel)
- [ ] Documentar padr√µes de nomenclatura da equipe

---

## üéØ Conclus√£o

O pipeline agora √©:
- ‚úÖ **Mais flex√≠vel**: Aceita qualquer nome de arquivo
- ‚úÖ **Mais simples**: Sem Unity Catalog
- ‚úÖ **Mais autom√°tico**: Descompacta ZIPs sozinho
- ‚úÖ **Mais robusto**: Schema evolution habilitado
- ‚úÖ **Mesmo desempenho**: CDF + Liquid Clustering intactos

**Compatibilidade total com atualiza√ß√£o mensal incremental!** üöÄ
