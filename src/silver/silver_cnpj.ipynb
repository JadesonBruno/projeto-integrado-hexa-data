{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a95ed3fe-a87a-4b1a-acf1-818d8f278488",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Imports e Configura√ß√£o\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "from datetime import datetime\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SilverCNPJ\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53901e93-b1d4-4fba-b47e-a29e0822b274",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC ## 2. Configura√ß√£o de Storage (ABFSS - ADLS Gen2)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# ‚úÖ Recuperar Storage Account\n",
    "TGT_STORAGE_ACCOUNT = dbutils.secrets.get(scope=\"acelera-grupo-5-kv\", key=\"tgt-storage-account\")\n",
    "\n",
    "# ‚úÖ Containers\n",
    "SILVER_CONTAINER = \"silver\"\n",
    "\n",
    "# ‚úÖ USAR ABFSS:// (Azure Data Lake Storage Gen2) - MESMO PROTOCOLO DO BRONZE\n",
    "SILVER_BASE_PATH = f\"abfss://{SILVER_CONTAINER}@{TGT_STORAGE_ACCOUNT}.dfs.core.windows.net/cnpj\"\n",
    "CONTROL_TABLE_PATH = f\"abfss://{SILVER_CONTAINER}@{TGT_STORAGE_ACCOUNT}.dfs.core.windows.net/metadata/silver_control_cnpj\"\n",
    "\n",
    "print(f\"‚úÖ Storage Account: {TGT_STORAGE_ACCOUNT}\")\n",
    "print(f\"‚úÖ Silver Container: {SILVER_CONTAINER}\")\n",
    "print(f\"‚úÖ Protocolo: abfss:// (ADLS Gen2)\")\n",
    "print(f\"üìÇ Silver Base Path: {SILVER_BASE_PATH}\")\n",
    "print(f\"üìÇ Control Table Path: {CONTROL_TABLE_PATH}\")\n",
    "print(f\"üóÑÔ∏è Bronze: Leitura via Hive Metastore (bronze)\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# üß™ VALIDAR ACESSO ao container Silver\n",
    "print(\"\\nüß™ Validando acesso ao container silver...\")\n",
    "\n",
    "try:\n",
    "    test_path = f\"abfss://{SILVER_CONTAINER}@{TGT_STORAGE_ACCOUNT}.dfs.core.windows.net/\"\n",
    "    files = dbutils.fs.ls(test_path)\n",
    "    print(f\"‚úÖ Container 'silver' acess√≠vel - {len(files)} itens encontrados\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO: Cluster n√£o tem acesso ao container 'silver'\")\n",
    "    print(f\"\\n‚ö†Ô∏è Verifique:\")\n",
    "    print(f\"   1. Container 'silver' existe no Storage Account\")\n",
    "    print(f\"   2. Service Principal/Managed Identity tem permiss√µes\")\n",
    "    print(f\"   3. Role necess√°ria: 'Storage Blob Data Contributor'\")\n",
    "    print(f\"\\nErro: {str(e)[:300]}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d242aeea-c69b-4bad-ac8d-a9d57a6682b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC ## 3. Otimiza√ß√µes Spark\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "spark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.databricks.delta.autoCompact.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "878f5990-c9b0-4e51-8d81-b1bcc8c7f348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC ## 4. Cria√ß√£o de Databases\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS silver\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS metadata\")\n",
    "\n",
    "print(\"‚úÖ Databases criados no Hive Metastore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cf91896-0626-4a70-b12e-98ce14d77dee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC ## 5. Cria√ß√£o da Tabela de Controle\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS metadata.silver_control_cnpj (\n",
    "        table_name STRING COMMENT 'Nome da tabela Silver',\n",
    "        last_ingestion_timestamp TIMESTAMP COMMENT '√öltimo timestamp processado',\n",
    "        last_update TIMESTAMP COMMENT 'Timestamp da √∫ltima atualiza√ß√£o',\n",
    "        records_processed BIGINT COMMENT 'Total de registros processados',\n",
    "        execution_id STRING COMMENT 'ID da execu√ß√£o'\n",
    "    )\n",
    "    USING DELTA\n",
    "    LOCATION '{CONTROL_TABLE_PATH}'\n",
    "    COMMENT 'Controle incremental - Silver CNPJ'\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Tabela de controle criada\")\n",
    "\n",
    "# Verificar location\n",
    "location = spark.sql(\"DESCRIBE DETAIL metadata.silver_control_cnpj\").select(\"location\").first()[0]\n",
    "print(f\"üìÇ Location: {location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "351e46dd-a260-4b68-a8a2-6fe8e55afcd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC ## 6. Configura√ß√£o de Transforma√ß√µes\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "table_config = [\n",
    "    # ========================\n",
    "    # CNAE\n",
    "    # ========================\n",
    "    {\n",
    "        \"bronze_table\": \"cnaes\",\n",
    "        \"silver_table\": \"cnaes\",\n",
    "        \"key_columns\": [\"codigo_cnae\"],\n",
    "        \"column_mapping\": {\n",
    "            \"codigo_cnae\": {\"rename\": \"codigo_cnae\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"descricao_cnae\": {\"rename\": \"descricao_cnae\", \"cast\": \"string\", \"trim\": True}\n",
    "        },\n",
    "        \"partition_by\": None,\n",
    "        \"description\": \"Classifica√ß√£o Nacional de Atividades Econ√¥micas (CNAE)\"\n",
    "    },\n",
    "\n",
    "    # ========================\n",
    "    # EMPRESAS\n",
    "    # ========================\n",
    "    {\n",
    "        \"bronze_table\": \"empresas\",\n",
    "        \"silver_table\": \"empresas\",\n",
    "        \"key_columns\": [\"cnpj_basico\"],\n",
    "        \"column_mapping\": {\n",
    "            \"cnpj_basico\": {\"rename\": \"cnpj_basico\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"razao_social\": {\"rename\": \"razao_social\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"natureza_juridica\": {\"rename\": \"natureza_juridica\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"qualificacao_responsavel\": {\"rename\": \"qualificacao_responsavel\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"capital_social\": {\"rename\": \"capital_social\", \"cast\": \"decimal(18,2)\", \"trim\": False},\n",
    "            \"porte_empresa\": {\"rename\": \"porte_empresa\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"ente_federativo_responsavel\": {\"rename\": \"ente_federativo_responsavel\", \"cast\": \"string\", \"trim\": True}\n",
    "        },\n",
    "        \"partition_by\": None,\n",
    "        \"description\": \"Dados cadastrais das empresas (n√≠vel CNPJ b√°sico)\"\n",
    "    },\n",
    "\n",
    "    # ========================\n",
    "    # ESTABELECIMENTOS\n",
    "    # ========================\n",
    "    {\n",
    "        \"bronze_table\": \"estabelecimentos\",\n",
    "        \"silver_table\": \"estabelecimentos\",\n",
    "        \"key_columns\": [\"cnpj_basico\", \"cnpj_ordem\", \"cnpj_dv\"],\n",
    "        \"column_mapping\": {\n",
    "            \"cnpj_basico\": {\"rename\": \"cnpj_basico\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"cnpj_ordem\": {\"rename\": \"cnpj_ordem\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"cnpj_dv\": {\"rename\": \"cnpj_dv\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"identificador_matriz_filial\": {\"rename\": \"identificador_matriz_filial\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"nome_fantasia\": {\"rename\": \"nome_fantasia\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"situacao_cadastral\": {\"rename\": \"situacao_cadastral\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"data_situacao_cadastral\": {\"rename\": \"data_situacao_cadastral\", \"cast\": \"date\", \"trim\": False},\n",
    "            \"motivo_situacao_cadastral\": {\"rename\": \"motivo_situacao_cadastral\", \"cast\": \"int\", \"trim\": False},\n",
    "            \"nome_cidade_exterior\": {\"rename\": \"nome_cidade_exterior\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"pais\": {\"rename\": \"pais\", \"cast\": \"int\", \"trim\": False},\n",
    "            \"data_inicio_atividade\": {\"rename\": \"data_inicio_atividade\", \"cast\": \"date\", \"trim\": False},\n",
    "            \"cnae_fiscal_principal\": {\"rename\": \"cnae_fiscal_principal\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"cnae_fiscal_secundaria\": {\"rename\": \"cnae_fiscal_secundaria\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"tipo_logradouro\": {\"rename\": \"tipo_logradouro\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"logradouro\": {\"rename\": \"logradouro\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"numero\": {\"rename\": \"numero\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"complemento\": {\"rename\": \"complemento\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"bairro\": {\"rename\": \"bairro\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"cep\": {\"rename\": \"cep\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"uf\": {\"rename\": \"uf\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"municipio\": {\"rename\": \"municipio\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"ddd_1\": {\"rename\": \"ddd1\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"telefone_1\": {\"rename\": \"telefone1\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"ddd_2\": {\"rename\": \"ddd2\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"telefone_2\": {\"rename\": \"telefone2\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"ddd_fax\": {\"rename\": \"ddd_fax\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"fax\": {\"rename\": \"fax\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"email\": {\"rename\": \"email\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"situacao_especial\": {\"rename\": \"situacao_especial\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"data_situacao_especial\": {\"rename\": \"data_situacao_especial\", \"cast\": \"date\", \"trim\": False}\n",
    "        },\n",
    "        \"partition_by\": [\"uf\"],\n",
    "        \"description\": \"Estabelecimentos vinculados ao CNPJ (matriz e filiais)\"\n",
    "    },\n",
    "\n",
    "    # ========================\n",
    "    # MOTIVOS\n",
    "    # ========================\n",
    "    {\n",
    "        \"bronze_table\": \"motivos\",\n",
    "        \"silver_table\": \"motivos\",\n",
    "        \"key_columns\": [\"codigo_motivo\"],\n",
    "        \"column_mapping\": {\n",
    "            \"codigo_motivo\": {\"rename\": \"codigo_motivo\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"descricao_motivo\": {\"rename\": \"descricao_motivo\", \"cast\": \"string\", \"trim\": True}\n",
    "        },\n",
    "        \"partition_by\": None,\n",
    "        \"description\": \"Motivos de situa√ß√£o cadastral\"\n",
    "    },\n",
    "\n",
    "    # ========================\n",
    "    # MUNIC√çPIOS\n",
    "    # ========================\n",
    "    {\n",
    "        \"bronze_table\": \"municipios\",\n",
    "        \"silver_table\": \"municipios\",\n",
    "        \"key_columns\": [\"codigo_municipio\"],\n",
    "        \"column_mapping\": {\n",
    "            \"codigo_municipio\": {\"rename\": \"codigo_municipio\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"descricao_municipio\": {\"rename\": \"descricao_municipio\", \"cast\": \"string\", \"trim\": True}\n",
    "        },\n",
    "        \"partition_by\": None,\n",
    "        \"description\": \"Cadastro de munic√≠pios do Brasil\"\n",
    "    },\n",
    "\n",
    "    # ========================\n",
    "    # NATUREZAS JUR√çDICAS\n",
    "    # ========================\n",
    "    {\n",
    "        \"bronze_table\": \"naturezas\",\n",
    "        \"silver_table\": \"naturezas\",\n",
    "        \"key_columns\": [\"codigo_natureza_juridica\"],\n",
    "        \"column_mapping\": {\n",
    "            \"codigo_natureza_juridica\": {\"rename\": \"codigo_natureza_juridica\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"descricao_natureza_juridica\": {\"rename\": \"descricao_natureza_juridica\", \"cast\": \"string\", \"trim\": True}\n",
    "        },\n",
    "        \"partition_by\": None,\n",
    "        \"description\": \"Naturezas jur√≠dicas das empresas\"\n",
    "    },\n",
    "\n",
    "    # ========================\n",
    "    # PA√çSES\n",
    "    # ========================\n",
    "    {\n",
    "        \"bronze_table\": \"paises\",\n",
    "        \"silver_table\": \"paises\",\n",
    "        \"key_columns\": [\"codigo_pais\"],\n",
    "        \"column_mapping\": {\n",
    "            \"codigo_pais\": {\"rename\": \"codigo_pais\", \"cast\":\"string\",\"trim\": False},\n",
    "            \"descricao_pais\": {\"rename\": \"descricao_pais\", \"cast\": \"string\", \"trim\": True}\n",
    "        },\n",
    "        \"partition_by\": None,\n",
    "        \"description\": \"Cadastro de pa√≠ses\"\n",
    "    },\n",
    "\n",
    "    # ========================\n",
    "    # QUALIFICA√á√ïES\n",
    "    # ========================\n",
    "    {\n",
    "        \"bronze_table\": \"qualificacoes\",\n",
    "        \"silver_table\": \"qualificacoes\",\n",
    "        \"key_columns\": [\"codigo_qualificacao\"],\n",
    "        \"column_mapping\": {\n",
    "            \"codigo_qualificacao\": {\"rename\": \"codigo_qualificacao\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"descricao_qualificacao\": {\"rename\": \"descricao_qualificacao\", \"cast\": \"string\", \"trim\": True}\n",
    "        },\n",
    "        \"partition_by\": None,\n",
    "        \"description\": \"Qualifica√ß√µes de s√≥cios e respons√°veis legais\"\n",
    "    },\n",
    "\n",
    "    # ========================\n",
    "    # SIMPLES / MEI\n",
    "    # ========================\n",
    "    {\n",
    "        \"bronze_table\": \"simples\",\n",
    "        \"silver_table\": \"simples\",\n",
    "        \"key_columns\": [\"cnpj_basico\"],\n",
    "        \"column_mapping\": {\n",
    "            \"cnpj_basico\": {\"rename\": \"cnpj_basico\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"opcao_simples\": {\"rename\": \"opcao_simples\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"data_opcao_simples\": {\"rename\": \"data_opcao_simples\", \"cast\": \"date\", \"trim\": False},\n",
    "            \"data_exclusao_simples\": {\"rename\": \"data_exclusao_simples\", \"cast\": \"date\", \"trim\": False},\n",
    "            \"opcao_mei\": {\"rename\": \"opcao_mei\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"data_opcao_mei\": {\"rename\": \"data_opcao_mei\", \"cast\": \"date\", \"trim\": False},\n",
    "            \"data_exclusao_mei\": {\"rename\": \"data_exclusao_mei\", \"cast\": \"date\", \"trim\": False}\n",
    "        },\n",
    "        \"partition_by\": None,\n",
    "        \"description\": \"Op√ß√£o pelo Simples Nacional e MEI\"\n",
    "    },\n",
    "\n",
    "    # ========================\n",
    "    # S√ìCIOS\n",
    "    # ========================\n",
    "    {\n",
    "        \"bronze_table\": \"socios\",\n",
    "        \"silver_table\": \"socios\",\n",
    "        \"key_columns\": [\"cnpj_basico\", \"cpf_cnpj_socio\"],\n",
    "        \"column_mapping\": {\n",
    "            \"cnpj_basico\": {\"rename\": \"cnpj_basico\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"identificador_socio\": {\"rename\": \"identificador_socio\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"nome_socio_razao_social\": {\"rename\": \"nome_socio_razao_social\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"cpf_cnpj_socio\": {\"rename\": \"cpf_cnpj_socio\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"qualificacao_socio\": {\"rename\": \"qualificacao_socio\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"data_entrada_sociedade\": {\"rename\": \"data_entrada_sociedade\", \"cast\": \"date\", \"trim\": False},\n",
    "            \"pais\": {\"rename\": \"pais\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"cpf_representante_legal\": {\"rename\": \"cpf_representante_legal\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"nome_representante_legal\": {\"rename\": \"nome_representante_legal\", \"cast\": \"string\", \"trim\": True},\n",
    "            \"qualificacao_representante_legal\": {\"rename\": \"qualificacao_representante_legal\", \"cast\": \"string\", \"trim\": False},\n",
    "            \"faixa_etaria\": {\"rename\": \"faixa_etaria\", \"cast\": \"int\", \"trim\": False}\n",
    "        },\n",
    "        \"partition_by\": None,\n",
    "        \"description\": \"Quadro societ√°rio das empresas\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ {len(table_config)} tabelas configuradas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15653cf5-359c-40d8-83e8-25cf7ddcc74b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC ## 7. Fun√ß√µes de Transforma√ß√£o\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "def get_last_processed_timestamp(silver_table_name: str) -> datetime:\n",
    "    \"\"\"\n",
    "    Recupera √∫ltimo timestamp processado da tabela de controle\n",
    "    \n",
    "    Args:\n",
    "        silver_table_name: Nome da tabela Silver\n",
    "        \n",
    "    Returns:\n",
    "        √öltimo timestamp processado ou None se primeira execu√ß√£o\n",
    "    \"\"\"\n",
    "    try:\n",
    "        row = (\n",
    "            spark.table(\"metadata.silver_control_cnpj\")\n",
    "            .filter(F.col(\"table_name\") == silver_table_name)\n",
    "            .select(\"last_ingestion_timestamp\")\n",
    "            .orderBy(F.col(\"last_update\").desc())\n",
    "            .limit(1)\n",
    "            .collect()\n",
    "        )\n",
    "        \n",
    "        if row:\n",
    "            timestamp = row[0][\"last_ingestion_timestamp\"]\n",
    "            print(f\"üìÖ √öltimo processamento: {timestamp}\")\n",
    "            return timestamp\n",
    "        else:\n",
    "            print(f\"üÜï Primeira execu√ß√£o\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Controle vazio: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_bronze_incremental_latest(bronze_table: str, pk_columns: list, last_processed_at: datetime):\n",
    "    \"\"\"\n",
    "    L√™ dados incrementais do Bronze via HIVE METASTORE\n",
    "    \n",
    "    Args:\n",
    "        bronze_table: Nome da tabela Bronze (sem database)\n",
    "        pk_columns: Lista de colunas da chave prim√°ria\n",
    "        last_processed_at: Timestamp do √∫ltimo processamento (watermark)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame com dados novos (DEDUPLICA√á√ÉO SER√Å FEITA DEPOIS DA TRANSFORMA√á√ÉO)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ‚úÖ Leitura via Hive Metastore\n",
    "    full_table_name = f\"bronze.{bronze_table}\"\n",
    "    \n",
    "    try:\n",
    "        df_bronze = spark.table(full_table_name)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Tabela Bronze n√£o existe: {full_table_name}\")\n",
    "        raise\n",
    "    \n",
    "    # Filtro incremental usando _ingestion_timestamp (nome correto do Bronze)\n",
    "    if last_processed_at:\n",
    "        df_filtered = df_bronze.filter(F.col(\"_ingestion_timestamp\") > F.lit(last_processed_at))\n",
    "        records_filtered = df_filtered.count()\n",
    "        print(f\"üìä Registros incrementais: {records_filtered:,}\")\n",
    "    else:\n",
    "        df_filtered = df_bronze\n",
    "        records_total = df_filtered.count()\n",
    "        print(f\"üìä Carga FULL: {records_total:,}\")\n",
    "    \n",
    "    # ‚úÖ RETORNA SEM DEDUPLICA√á√ÉO\n",
    "    # A deduplica√ß√£o ser√° feita DEPOIS da transforma√ß√£o de colunas\n",
    "    # para evitar conflito entre nomes Bronze e Silver\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def apply_column_mapping(df, column_mapping: dict):\n",
    "    \"\"\"\n",
    "    Aplica transforma√ß√µes de colunas (cast, rename, trim)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame Bronze\n",
    "        column_mapping: Dicion√°rio com regras de transforma√ß√£o\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame transformado\n",
    "    \"\"\"\n",
    "    select_exprs = []\n",
    "    \n",
    "    for source_col, rules in column_mapping.items():\n",
    "        if source_col not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è Coluna {source_col} n√£o encontrada - ignorando\")\n",
    "            continue\n",
    "        \n",
    "        # Suporte para mapeamento simples (string)\n",
    "        if isinstance(rules, str):\n",
    "            select_exprs.append(F.col(source_col).alias(rules))\n",
    "            continue\n",
    "        \n",
    "        # Mapeamento completo (dict)\n",
    "        target_col = rules.get(\"rename\", source_col)\n",
    "        cast_type = rules.get(\"cast\")\n",
    "        trim_flag = rules.get(\"trim\", False)\n",
    "        \n",
    "        col_expr = F.col(source_col)\n",
    "        \n",
    "        # Aplicar trim se string\n",
    "        if trim_flag:\n",
    "            col_expr = F.trim(col_expr)\n",
    "        \n",
    "        # ‚úÖ TRATAMENTO ESPECIAL PARA DATAS (formato AAAAMMDD)\n",
    "        if cast_type == \"date\":\n",
    "            # Converter string AAAAMMDD para DATE\n",
    "            # Exemplo: \"20210315\" -> 2021-03-15\n",
    "            col_expr = F.to_date(col_expr, \"yyyyMMdd\")\n",
    "        elif cast_type:\n",
    "            # Aplicar cast normal para outros tipos\n",
    "            col_expr = col_expr.cast(cast_type)\n",
    "        \n",
    "        select_exprs.append(col_expr.alias(target_col))\n",
    "    \n",
    "    # Preservar metadados t√©cnicos (NOMES CORRETOS DO BRONZE)\n",
    "    technical_cols = [\"ingestion_date\", \"_ingestion_timestamp\", \"_source_path\"]\n",
    "    for col_name in technical_cols:\n",
    "        if col_name in df.columns:\n",
    "            select_exprs.append(F.col(col_name))\n",
    "    \n",
    "    # ‚úÖ ADICIONAR TIMESTAMP DE INSER√á√ÉO NA SILVER\n",
    "    select_exprs.append(F.current_timestamp().alias(\"_silver_timestamp\"))\n",
    "    \n",
    "    return df.select(*select_exprs)\n",
    "\n",
    "\n",
    "def deduplicate_by_pk(df, pk_columns: list):\n",
    "    \"\"\"\n",
    "    Deduplica DataFrame por chave prim√°ria (mant√©m registro mais recente)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame j√° transformado (com nomes Silver)\n",
    "        pk_columns: Lista de colunas da chave prim√°ria (nomes Silver)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame deduplicado\n",
    "    \"\"\"\n",
    "    \n",
    "    # Window por PK, ordenado por timestamp descendente\n",
    "    window_pk = Window.partitionBy(*pk_columns).orderBy(F.col(\"_ingestion_timestamp\").desc())\n",
    "    \n",
    "    df_dedup = (\n",
    "        df\n",
    "        .withColumn(\"_rn\", F.row_number().over(window_pk))\n",
    "        .filter(F.col(\"_rn\") == 1)\n",
    "        .drop(\"_rn\")\n",
    "    )\n",
    "    \n",
    "    records_dedup = df_dedup.count()\n",
    "    print(f\"‚úÖ Registros √∫nicos ap√≥s deduplica√ß√£o: {records_dedup:,}\")\n",
    "    \n",
    "    return df_dedup\n",
    "\n",
    "\n",
    "def merge_into_silver(df_source, silver_table_name: str, pk_columns: list, partition_by: list):\n",
    "    \"\"\"\n",
    "    Executa MERGE na Silver e registra no Hive Metastore\n",
    "    \n",
    "    Args:\n",
    "        df_source: DataFrame transformado\n",
    "        silver_table_name: Nome da tabela Silver (ex: 'silver_empresas')\n",
    "        pk_columns: Colunas da chave prim√°ria\n",
    "        partition_by: Colunas para particionamento (ou None)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Path f√≠sico no ADLS Gen2\n",
    "    silver_path = f\"{SILVER_BASE_PATH}/{silver_table_name}\"\n",
    "    full_table_name = f\"silver.{silver_table_name}\"\n",
    "    \n",
    "    # Verificar se tabela existe\n",
    "    if not DeltaTable.isDeltaTable(spark, silver_path):\n",
    "        print(f\"üÜï Criando tabela: {full_table_name}\")\n",
    "        \n",
    "        # Escrever arquivos Delta\n",
    "        writer = df_source.write.format(\"delta\").mode(\"overwrite\")\n",
    "        \n",
    "        if partition_by:\n",
    "            writer = writer.partitionBy(*partition_by)\n",
    "            print(f\"üìÇ Particionamento: {partition_by}\")\n",
    "        \n",
    "        writer.save(silver_path)\n",
    "        \n",
    "        # ‚úÖ Registrar no Hive Metastore\n",
    "        spark.sql(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {full_table_name}\n",
    "            USING DELTA\n",
    "            LOCATION '{silver_path}'\n",
    "        \"\"\")\n",
    "        \n",
    "        print(f\"‚úÖ Tabela criada e registrada no Hive\")\n",
    "        return\n",
    "    \n",
    "    # MERGE incremental (SCD Type 1)\n",
    "    print(f\"üîÑ Executando MERGE: {full_table_name}\")\n",
    "    \n",
    "    delta_silver = DeltaTable.forPath(spark, silver_path)\n",
    "    merge_condition = \" AND \".join([f\"silver.{pk} = source.{pk}\" for pk in pk_columns])\n",
    "    \n",
    "    # Colunas para update (todas exceto PKs)\n",
    "    update_columns = {col: f\"source.{col}\" for col in df_source.columns if col not in pk_columns}\n",
    "    \n",
    "    # Colunas para insert (todas)\n",
    "    insert_columns = {col: f\"source.{col}\" for col in df_source.columns}\n",
    "    \n",
    "    (\n",
    "        delta_silver.alias(\"silver\")\n",
    "        .merge(df_source.alias(\"source\"), merge_condition)\n",
    "        .whenMatchedUpdate(set=update_columns)\n",
    "        .whenNotMatchedInsert(values=insert_columns)\n",
    "        .execute()\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ MERGE conclu√≠do\")\n",
    "\n",
    "\n",
    "def update_control_table(silver_table_name: str, max_timestamp: datetime, records_count: int, execution_id: str):\n",
    "    \"\"\"\n",
    "    Atualiza tabela de controle com watermark\n",
    "    \n",
    "    Args:\n",
    "        silver_table_name: Nome da tabela Silver\n",
    "        max_timestamp: Timestamp m√°ximo processado\n",
    "        records_count: Quantidade de registros processados\n",
    "        execution_id: ID da execu√ß√£o\n",
    "    \"\"\"\n",
    "    \n",
    "    # ‚úÖ CALCULAR timestamp atual ANTES de criar tupla\n",
    "    current_ts = datetime.now()\n",
    "    \n",
    "    control_data = [(silver_table_name, max_timestamp, current_ts, records_count, execution_id)]\n",
    "    df_new = spark.createDataFrame(\n",
    "        control_data,\n",
    "        [\"table_name\", \"last_ingestion_timestamp\", \"last_update\", \"records_processed\", \"execution_id\"]\n",
    "    )\n",
    "    \n",
    "    if DeltaTable.isDeltaTable(spark, CONTROL_TABLE_PATH):\n",
    "        delta_control = DeltaTable.forPath(spark, CONTROL_TABLE_PATH)\n",
    "        \n",
    "        (\n",
    "            delta_control.alias(\"t\")\n",
    "            .merge(df_new.alias(\"s\"), \"t.table_name = s.table_name\")\n",
    "            .whenMatchedUpdate(set={\n",
    "                \"last_ingestion_timestamp\": \"s.last_ingestion_timestamp\",\n",
    "                \"last_update\": \"s.last_update\",\n",
    "                \"records_processed\": \"t.records_processed + s.records_processed\",\n",
    "                \"execution_id\": \"s.execution_id\"\n",
    "            })\n",
    "            .whenNotMatchedInsert(values={\n",
    "                \"table_name\": \"s.table_name\",\n",
    "                \"last_ingestion_timestamp\": \"s.last_ingestion_timestamp\",\n",
    "                \"last_update\": \"s.last_update\",\n",
    "                \"records_processed\": \"s.records_processed\",\n",
    "                \"execution_id\": \"s.execution_id\"\n",
    "            })\n",
    "            .execute()\n",
    "        )\n",
    "        \n",
    "        print(f\"üìù Controle atualizado\")\n",
    "    else:\n",
    "        df_new.write.format(\"delta\").mode(\"overwrite\").save(CONTROL_TABLE_PATH)\n",
    "        print(f\"üÜï Controle inicializado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a253d99-9abd-4913-8f22-55ddc454b5f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC ## 8. Processamento Incremental\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "execution_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"üöÄ Execution ID: {execution_id}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Estat√≠sticas da execu√ß√£o\n",
    "total_tables_processed = 0\n",
    "total_records_processed = 0\n",
    "tables_created = []\n",
    "tables_updated = []\n",
    "tables_failed = []\n",
    "\n",
    "for config in table_config:\n",
    "    \n",
    "    bronze_table = config[\"bronze_table\"]\n",
    "    silver_table = config[\"silver_table\"]\n",
    "    pk_cols = config[\"key_columns\"]\n",
    "    column_mapping = config[\"column_mapping\"]\n",
    "    partition_by = config[\"partition_by\"]\n",
    "    description = config[\"description\"]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìã Bronze: bronze.{bronze_table}\")\n",
    "    print(f\"üìã Silver: silver.{silver_table}\")\n",
    "    print(f\"üìù Descri√ß√£o: {description}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Verificar se Bronze existe\n",
    "        try:\n",
    "            spark.table(f\"bronze.{bronze_table}\").limit(1).count()\n",
    "        except:\n",
    "            print(f\"‚ö†Ô∏è Tabela Bronze n√£o existe: bronze.{bronze_table}\")\n",
    "            tables_failed.append(silver_table)\n",
    "            continue\n",
    "        \n",
    "        # 2. Recuperar √∫ltimo timestamp processado\n",
    "        last_processed_at = get_last_processed_timestamp(silver_table)\n",
    "        \n",
    "        # 3. Ler dados incrementais do Bronze (SEM deduplica√ß√£o ainda)\n",
    "        df_latest = get_bronze_incremental_latest(bronze_table, pk_cols, last_processed_at)\n",
    "        \n",
    "        # 4. Verificar se h√° dados novos\n",
    "        if df_latest.count() == 0:\n",
    "            print(f\"‚ÑπÔ∏è Sem dados novos para processar\")\n",
    "            continue\n",
    "        \n",
    "        # 5. Aplicar transforma√ß√µes (rename, cast, trim)\n",
    "        df_transformed = apply_column_mapping(df_latest, column_mapping)\n",
    "        \n",
    "        # 6. ‚úÖ DEDUPLICAR AP√ìS TRANSFORMA√á√ÉO (com nomes Silver corretos)\n",
    "        df_transformed = deduplicate_by_pk(df_transformed, pk_cols)\n",
    "        \n",
    "        # 7. Verificar se √© tabela nova\n",
    "        is_new_table = not spark.catalog.tableExists(f\"silver.{silver_table}\")\n",
    "        \n",
    "        # 8. MERGE na Silver\n",
    "        merge_into_silver(df_transformed, silver_table, pk_cols, partition_by)\n",
    "        \n",
    "        # 9. Atualizar controle\n",
    "        max_timestamp = df_transformed.agg(F.max(\"_ingestion_timestamp\")).collect()[0][0]\n",
    "        records_count = df_transformed.count()\n",
    "        \n",
    "        update_control_table(silver_table, max_timestamp, records_count, execution_id)\n",
    "        \n",
    "        # 10. Registrar estat√≠sticas\n",
    "        total_tables_processed += 1\n",
    "        total_records_processed += records_count\n",
    "        \n",
    "        if is_new_table:\n",
    "            tables_created.append(silver_table)\n",
    "        else:\n",
    "            tables_updated.append(silver_table)\n",
    "        \n",
    "        print(f\"‚úÖ {silver_table} processado com sucesso!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERRO ao processar {silver_table}\")\n",
    "        print(f\"   Erro: {str(e)}\")\n",
    "        tables_failed.append(silver_table)\n",
    "        \n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üéâ PROCESSAMENTO CONCLU√çDO\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc23ce51-cd5f-48b9-a68d-2c3bf302a3df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC ## 9. Relat√≥rio de Execu√ß√£o\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                  RELAT√ìRIO - SILVER CNPJ                         ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "üìä ESTAT√çSTICAS GERAIS:\n",
    "   ‚Ä¢ Execution ID: {execution_id}\n",
    "   ‚Ä¢ Tabelas processadas: {total_tables_processed}\n",
    "   ‚Ä¢ Registros processados: {total_records_processed:,}\n",
    "   ‚Ä¢ Protocolo: abfss:// (ADLS Gen2)\n",
    "\n",
    "‚úÖ TABELAS CRIADAS ({len(tables_created)}):\n",
    "{chr(10).join(f'   ‚Ä¢ {t}' for t in tables_created) if tables_created else '   (nenhuma)'}\n",
    "\n",
    "üîÑ TABELAS ATUALIZADAS ({len(tables_updated)}):\n",
    "{chr(10).join(f'   ‚Ä¢ {t}' for t in tables_updated) if tables_updated else '   (nenhuma)'}\n",
    "\n",
    "{f'‚ùå TABELAS COM FALHA ({len(tables_failed)}):' if tables_failed else ''}\n",
    "{chr(10).join(f'   ‚Ä¢ {t}' for t in tables_failed) if tables_failed else ''}\n",
    "\n",
    "üóÑÔ∏è ARQUITETURA:\n",
    "   ‚Ä¢ Bronze (leitura): Hive Metastore ‚Üí bronze_cnpj.*\n",
    "   ‚Ä¢ Silver (escrita): ADLS Gen2 + Hive ‚Üí silver_cnpj.*\n",
    "   ‚Ä¢ Controle: metadata.silver_control_cnpj\n",
    "\n",
    "üìÇ LOCALIZA√á√ÉO F√çSICA:\n",
    "   ‚Ä¢ Silver Tables: {SILVER_BASE_PATH}\n",
    "   ‚Ä¢ Control Table: {CONTROL_TABLE_PATH}\n",
    "\n",
    "üîó CONEX√ÉO POWER BI:\n",
    "   ‚Ä¢ Catalog: hive_metastore\n",
    "   ‚Ä¢ Schema: silver\n",
    "   ‚Ä¢ Autentica√ß√£o: Configurada no cluster (Service Principal/Managed Identity)\n",
    "\n",
    "‚è±Ô∏è PR√ìXIMA EXECU√á√ÉO:\n",
    "   ‚Ä¢ Apenas dados com _ingestion_timestamp > √∫ltimo processamento\n",
    "   ‚Ä¢ Processamento incremental autom√°tico\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22bfeb18-c816-4370-a58a-dcbbbf93118f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS silver.corr_ncm_cnae;\n",
    "\n",
    "CREATE TABLE silver.corr_ncm_cnae\n",
    "USING DELTA\n",
    "LOCATION 'abfss://silver@aceleragrupo5sa.dfs.core.windows.net/corr_ncm_cnae'\n",
    "AS SELECT * FROM bronze.corr_ncm_cnae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc1daa50-44fb-4318-9cee-96d04211390a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6772614138689748,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_cnpj",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
